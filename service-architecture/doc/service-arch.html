<html>



<h2>Eucalyptus Service Architecture</h2>

Eucalyptus is organized a tiered ensemble of web services.  This missive
outlines the organization of these services and the messaging 
interaction that takes place between these services in
response to user requests.
<p>
To begin with, it is important to understand that difference between a service
and a container within the Eucalyptus architecture.  At its core,
Eucalyptus uses an
<a href="http://en.wikipedia.org/wiki/Enterprise_service_bus">
Enterprise Service Bus</a> model as the basis for its architecture.  Service
components "plug into" a universal naming and messaging software substrate
that separates (abstracts away) communication and location functions
throughout the ensemble.  As a result, all services "see" a common framework
that handles secure message routing and delivery, regardless of physical
location.

<h2>Enterprise Service Bus and Eucalyptus Service Components</h2>

The service bus is implemented as a logical communication channel between web
service containers that are, in turn, run by web servers.  The web service
containers take care of message intergrity, security, and dispatch and the web
servers take care of manageing the container lifecycle (starting a container,
stopping a container, etc.)
<p>
Thus, at a high level, the message flow between <i>any</i> two internal
Eucayptus services that are located on separate machines is
<ul>
<li> the sending service components puts the message on the Enterprise Bus
<li> the Enterprise Bus calls the web service stack to implement the
communication
<li> the web service stack uses the web server to connect to the network and
send the message to another web server
<li> the receiving web server hands the message to the receiving web 
service stack
<li> the receiving stack puts the message on the Enterprise Bus
<li> the receiving service gets the message from the Enterprise Bus
</ul>
However, if the services are located on the same machine they work in exactly
same way (they do not need to be specialized for local and remote
communication) because of the bus.  Indeed, the implementation of the
Enterprise bus short-cuts the message path to bypass the web service stack and
to deliver the message directly when two services are co-located and they are
both written in Java.  For this
reason, services that are running on the same physical machine run in the 
same Java virtual machine.  If the services are written in different languages
(C and Java, for example) then they must use the full stack and communicate
using local Linux networking via sockets.
<p>
Note that this model is asynchronous which means that all service components
must supply a "call back" handler for the bus to call when a message is to be
delivered.  All Eucalyptus software components, fundamentally, use this
bus-style architecture to communicate.  That is, regardless of the service,
the Eucalyptus code that implements the service interfaces to the bus, both to
send messages to other components, and to receive messages via call backs, and
the bus and the web service software take care of securely transmitting the
information in a single, uniform way.

<h2>Major Eucalyptus Service Components</h2>

Eucalyptus consists of 7 major service components:
<ul>
<li><b>The Cloud Controller (CLC)</b> -- The CLC implements request processing
for all AWS EC2 requests.  It also coordinates the Eucalyptus secure 
bootstrapping and component registartion protocol.
<li><b>EUARE</b> -- The EUARE service implements the Eucalyptus identity
management system.  EUARE is compatible with the AWS Identity Access
Management (IAM) API.  It also includes extensions specifically added for
enterprise clouds such as resource quotas.
<li><b>Walrus</b> -- Walrus implements object storage for Eucalyptus.  It is
interface compatible with the AWS Simple Storage Service (S3).
<li><b>The Cluster Controller (CC)</b> -- The CC implements the
Eucalyptus-internal software defined networking subsystem that virtualizes the
network used by virtual machines (VMs) that are 
hosted within the Eucalyptus cloud.  It also
implements VM scheduling for a partition of the compute resources (often
termed a "cluster") within the overall Eucalyptus cloud.
<li><b>The VMWare Broker</b> -- The VMWare broker acts as a gateway between
the CC and VMWare virtualization components and services.  
It exports the same
Eucalyptus-internal API as the Node Controller so that the CC can operate
either without including specialized functionality for either.
<li><b>The Storage Controller (SC)</b> -- The SC implements the Eucalyptus
Block Storage (EBS) protocol.  EBS is compatible with the AWS Elastic Block
Store API, allowing virtual machines to attach block storage devices through
the cloud network.
<li><b>The Node Controller (NC)</b> -- The NC actuates virtual machines on
Linux machines that support an open source hypervisor.  It creates a bootable
instance from an image (stored in Walrus), configures the software defined
network, and attaches any block devices that the user requests.
</ul>
<p>
<img src=arch.png width=1000>
<p>
The Figure depicts the 7 Eucalyptus top level components and their messaging
relationships.  Each blue arrow indicates a message request from the requester
to the target.  The green arrows show which componets have access to a
distributed shared database service that is used to implement state
persistence (discussed below). 

<h3>The Eucalyptus Front End</h3>

Requests from users or the cloud administrators (left side of
the figure) are delivered
to the CLC, EUARE, or Walrus, depending on the specific call.  These
services collectively form the Eucalyptus "front end" or "top tier"
of a deployment.  The Eucalyptus
web service stack (not shown in the figure) takes care of message dispatch to
the appropriate service within the front end.  Walrus uses a <a
href="http://en.wikipedia.org/wiki/Category:Linux_file_systems">Linux file
system</a> as a storage medium for the objects it manages (depicted as an
inverted triangle in the figure).

<h3>The Eucalyptus Middle End</h3>

The CC, VMWare Broker, and SC compose the "middle end" or "middle tier" of a
Eucalyptus deployment.  The CLC sends VM provisioning commands to the CC and
block storage volume commands to the SC.  The CC communicates with the VMWare
Broker to actuate virtualization commands.  The CC also interacts with Linux
to implement Eucalyptus' software defined networking abstractions.  It manages
<a href="http://en.wikipedia.org/wiki/Iptables">Linux iptables rules</a>
to implement firewalls and address translation, 
<a href="http://linux-ip.net/html/routing-tables.html">Linux routing
tables</a> entries, a <a
href="http://www.yolinux.com/TUTORIALS/DHCP-Server.html">Linux DHCP
server</a>, and <a
href="http://www.techrepublic.com/article/linux-101-use-ifconfig-in-linux-to-configure-your-network/6040932">Linux
network interface state</a> by "shelling out" to a Linux system that will act
as a software router (typically the machine hosting the CC).  These
interactions with infrastructure outside of Eucalyptus (Linux and VMWare) are
depicted as inverted triangles in the figure. 
<p>
The SC sends snapshot storage requests to Walrus as snapshots are stored as
objects in Eucalyptus.

<h3>The Eucalyptus Back End</h3>

The back end of a Eucalyptus deployment is composed of Node Controllers (NCs).
Each host that uses a Linux system as a controlling domain (e.g. each host
running either a <a href="http://www.xen.org">Xen</a> or <a
href="http://www.linux-kvm.org/page/Main_Page">KVM</a> hypervisor) must host
an NC service.  The NC fields requests from the CC for VM, network, and block
storage acuation.  It requests images from Walrus, and sends volume attach and
detach requests to the SC.  The NC also interacts with the Linux system
hosting it via "shell outs" to implement instance caching.  These local Linux
interactions are depicted as inverted triangles in the figure.  

<h2>State Persistence</h2>

Eucalyptus is crash consistent which means that if any service is stopped due
to machine crash, software failure, network failure, etc. any internal state
necessary to allow the service to continue once it is able to run again is
persisted in a database (shown within the green circle in the figure).
Currently, all components have access to this distributed database service
except the CC and NC.  The CC is stateless, and the NC uses a local Linux file
to store a small amount of state associated with implementing a local instance
cache.  
<p>
To prevent the database from becoming a performance bottleneck, Eucalyptus
implements a two-level caching system.  All components using the database
service use <a
href="http://en.wikipedia.org/wiki/Hibernate_(Java)">Hibernate</a> to map
their Java objects to a relational database representation.  These objects are
stored in memory, but committed to the database (under Eucalyptus control) so
as to ensure causal consistency.  To further insulate Eucalyptus from the
potential of database congestion, objects are also stored 
<a href="http://docs.jboss.com/jbcache/1.2.4/TreeCache/html">Tree Cache</a> --
a component of <a href="http://www.jboss.org">JBOSS</a>.  Tree Cache
implements a distributed and replicated transactional object cache.  Thus an
object is replicated in memory across Java vitual machines as it is sent to
the database.
<p>
In addition to providing fast persistence to support crash consistency, this
persistence architecture is the basis of primary-backup High Availability (HA)
for the Eucalyptus platform itself.  The object persistence service (accessed
via a Eucalyptus-internal API) can be configured to use two separate database
installations as a synchronized backing store.  To determine which database is 
the currently active primary as well as to trigger a resynchronization after
database or network failure, the persistence stack uses <a
href="http://www.jgroups.org">Jgroups</a> to determine active component group
membership.

<h2>The Java Web Services Object Stack</h2>

The following figure shows the Java web service object stack.  
<p>
<img src=ws-stack.png width=1000>
<p>
Elements depicted in blue are Eucalyptus specific.  Elements shown in red are
implemented in conjunction with an existing
open source technology (shown in parentheses).  All Java
services within Eucalyptus use the functionality implemented by this stack.  
<p>
Note that while the data persistence service is built into the stack itself,
and hence is available to all Java components, the persistence layer <i><b>is
not</b></i> used as a communication medium.  That is, while each 
Eucalyptus service component written in Java has access to the distributed
object cache, they each use it individually for data persistence and not to
communicate data between services.  Messages between services carry all
necessary state instead.  This architectural decision makes it possible to
use different language technologies to implement future services (or service
replacements).  That is, a Eucalyptus service does not need to be able to
access Java objects in the persistence layer in order to be part of the 
overall system.

<h2>The Web Services Communication Stack</h2>

When a message must traverse outside of the web service container in which it
originates, the enterprise service bus uses a communication stack based on 
<a href="http://en.wikipedia.org/wiki/SOAP">SOAP</a>.  
<p>
<img src=ws-comm.png, width=1000>
<p>
The figure shown above depicts the functional decomposition of the
stack.  Note that the WS-Security policy defined for Eucalyptus 
implements message authentication but does not specify message encryption (for
performance reasons).  Thus control messages between non-colocated services
are authenticated using PKI, but they are not encrypted.
<p>
<h2>Control Path and Data Path</h2>

With one exception, the Eucalyptus service components are part of a control
plane and not in the the data path for cloud allocations.  The one exception
is that Walrus performs the image decryption step of the AWS AMI protocol for
an uncached image.  Thus each Eucalyptus service "actuates" the underlying
hardware and software infrastructure but does not, itself, participate in the
user's interaction with the resources that have been allocated. 
<p>
There are two implementation features of Eucalyptus, however that appear not
to conform to this design principle and as such, bear some clarification.
<p>
<h3>Firewalls, NATs, and the CC</h3>

The first concerns the implementation of software defined networking that
Eucalyptus supports.  For each VM in a security group, Eucalyptus must
provision a virtual network that is isolated at both layers 2 and 3.
This isolation is implemented by
<ul>
<li> attaching a VM to a Linux bridge that has been configured to use a VLAN
that is unique to the security group in which it runs
<li> ensuring that all VMs within a security group are on the same layer 3
subnetwork
<li> making the default route for the VMs in a security group route to a Linux
machines that Eucalyptus can use as a firewall and to implement network
address translation (NAT).
</ul>
Currently, the CC uses the Linux machine that is hosting it to implement the
firewall and NAT using iptables.  
Thus all network traffic that is between a VM and an IP
address outside of its security group traverses the firewall which is
controlled by the CC.  However the result is that the machine that is hosting
the CC is in the data path for non-internal security group IP traffic.
<p>
The Linux machine hosting the CC also implements the NAT for each VM.  Under
the AWS networking semantics, each VM receives a "private" IP and a "public"
IP.  the private IP is assigned to the VM's network interface and the public
IP is installed as a NAT in the data path between the VM and the publicly
routed network.  Eucalyptus implements this NAT on the Linux machine that acts
as a firewall (the Linux machine hosting the CC).

<h3>Implementing EBS using a Linux Host as the Storage Server</h3>

The other scenario in which a Linux machine hosting a Eucalyptus component is
potentially in the data path occurs when Eucalyptus is configured to use a
Linux host as the block storage server for EBS.  Eucalyptus supports a number
of different configurations for EBS using devices that can export iSCSI
targets.  The default configuration uses <a
href="http://stgt.sourceforge.net">Linux tgt</a> on the machine hosting the SC
to export an iSCSI target and then the <a
href="http://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)">Linux
Logical Volume Manager</a> and <a
href="http://en.wikipedia.org/wiki/Loop_device">Linux loop devices</a> to
provide file-backed volumes.  In this default configuration of Eucalyptus,
the SC commands the Linux machine hosting it to allocate and configure these
native Linux facilities.
<p>
While both the CC and the SC may rely on the "local" Linux host to implement
some functionality, neither the CC nor SC process itself is in the data path.
For example, once the CC installs iptables rules on the Linux machine hosting
it, the network traffic is handled by the Linux network stack without the CC
process in the data path.  Thus the CC and SC are true "controllers" and are
part of the control plane even when the machine that
hosts them is in the data path.

<h2>Request Processing</h2>

Eucalyptus services conform to a common three-stage architecture for request 
processing. 
<p>
<img src=service-message.png width=1000>
<p>
In the figure, the black arrows represent communication via method
invocation/function call and/or call backs.  The green arrow represents a
quesry to the "fulfilled" state, and the red arrows represent messages formed
and transmittted via the web service stack. 
<p>
When a user request arrives from a client tool, the web service stack 
takes care of authenticating the request.  
The request processing stage authorizes each request using 
an identifier that is associated with the user and the user's credentials.
(<a href="http://en.wikipedia.org/wiki/Public-key_infrastructure">
PKI</a> certificates.)  Certificate management (creation, deletion, etc.) is
implemented by a service component within the CLC (not shown in the 
architecture figure).
<p>
Once a request is authorized, the validity of the request
in terms of the parameters it references is checked.  For example, a
<code>euca-run-instances</code> command refers to a number of other resources
within a Eucalyptus cloud (an image, a kernel, a ram disk, a security group,
etc.)  The validation stage quesries the state in the "fulfilled" subsystem in
the
state management stage to
determine if these references are valid.
<p>
If the formation of the request is correct, it is
forwarded to a reservation subsystem where any necessary
capacity accounting is
performed.   Eucalyptus uses a conservative resource allocation policy when
ever possible.  Thus when a resource allocation request is made by a user, the
request processing stage "pre-allocates" the resource so that subsequent
requests are not accepted if resources will be eventually unavailable.  
Should the 
allocation
fail, the pre-allocation is reversed.
<p>
From the reservation stage, a success code is sent to the user indicating that
the request has been accepted by Eucalyptus and any information that
accompanies a response is returned.  
Authorization, validation, reservation are sequential and synchronous but any
actual
resource allocation itself occurs asynchronously.  If
the request is to allocate or to modify the allocation of a resource, then the
request is forwaded to the "in progress" subsystem in the state management
stage.
<p>
Eucalyptus records a request "in progress" before it is issued to an external
component for resource management. The response for such a request
is received
asynchronously.  Thus Eucalyptus marks an object as "in progress" and issues a
request to a resource allocation thread in the third stage to begin the
allocation request.
<p>
The resource allocation component makes an allocation request to the
resource (e.g. sends a message to another Eucalyptus process,
an external resource manager such as VMWare, or 
issues a Linux command).  Again, the effect of the request or command is
determined asynchronously.  The state update subsystem in the third stage
polls the resource for status and
updates an internal resource state object.  Once the entire request has been
fulfilled or has been determined to have failed, the resource update stage
contacts the resource allocation stage to indicate completion via a call
back stored in the object.  Resource
allocation notifies "in progress" of the status (again via call back), and 
the request moves to
"fulfilled" to indicate that Eucalyptus has either performed the allocation
request, or that it has failed definitively.  If and when a subsequent 
request for status or termination arrives, the appropriate status will be
returned to the user as a result of s read from the fulfilled state. 
<p>
Internally, the stages use the enterprise service bus to communicate.
As such, asynchronous communication is implemented via callbacks.  
Externally, services
poll for "ground truth."  That is, each service assumes that its internal data
models the state of a request, but that state can become "stale" at any
moment.  Thus, the service polls its external "resource" periodically to
resynchronize the data model.  This information synchronization methodology
obviates the need to implement reliable call backs, which is difficult to
implement in a crash consistent manner.

<h2>An Example: Running an Instance</h2>

The following sections illustrate how Eucalyptus functions in terms of 
its service architecture and message flow using the user request to run an
instance as an example.  The user command
<p>
<code>
euca-run-instance emi-id -n instance-count -k user-key
</code>
is a typical user request to run <i>instance-count</i> instances with the
specified user key using the Eucalyptus Machine Image (EMI) identified by
<i>emi-id</i>.
<p>
The web services communication stack, using WS-Security, first authenticates
the in-bound request.  If successful, it then performs message dispatch which,
in the case of <code>euca-run-instances</code>, delivers the message to the
CLC (it is an EC2 API request) and triggers the authorization subsystem in the
request processing stage.

<h3>CLC Request Processing Stage</h3>

Authorization determines whether the user is authorized to run an instance,
and if so, validates the request.  Validation must determine the default
values for any missing parameters and then validate that the full parameter
set refers to objects that are currently valid within the running Eucalyptus
deployment.
<p>
For <code>euca-run-instances</code> the full parameter set includes an
<i>eri-</i> (Eucalyptus Ramdisk Image), an <i>eki-</i> (Eucalyptus Kernel
Image), a default security group name, a virtual machine type, etc.  
Validation queries the
"fulfilled" object state to determine that all objects referenced are
currently instantiated within the system.  If a parameter is missing and there
is no default (e.g. the EMI is missing) or if the request refers to
non-existent objects, the request fails and an error is returned to the user.
<p>
Next, the reservation subsystem in the CLC Reqiuest Processing Stage checks to
make sure there are enough resources to allow the request to be accepted by
the system.  That is, it consults an accounting of the available "slots" for
the instance request that includes previous "pre-allocated" requests in
progress.  If there are enough resources available, the
reservation subsystem decrements the
available resources (makes a "pre-allocation" for this request) and
forwards the request
to the "in progress" subsystem in the state management stage.

<h3>CLC State Management Stage</h3>

In this example, the "in progress" stage notes that the request is pending and
immediately triggers a thread to run in the Resource Control stage in the
resource allocation subsystem.

<h3>CLC Resource Control Stage</h3>

The resource allocation subsystem formulates and sends a request to the 
CC for an instance run with the necsssary parameters (EMI, 
ERI, and EKI identifiers,
security group identifier, user identifier, public ssh key to inject in the VM
once it is launched, user meta data, etc.  The enterprise service bus
recognizes that the CC is not co-located with the CLC (the CC using C-language
web services and the CLC uses Java-language web services so they cannot be
co-located in the same Java virtual machine) and routes the message through
the network to the CC using the Web Services Communication Stack as a SOAP
message. 
<p>
A separate polling thread in the Resource State Update subsystem of the
Resource Control Stage in the CLC scans the
list of objects for which requests to the CC are outstanding.  On a fixed duty
cycle, these threads periodically send a message (again automatically routed as
a SOAP message) to the CC requesting status update for the outstanding
requests.

<h3>CC Request Processing</h3>

The request to run the instance is received in the CC as a SOAP message that
is authenticated using WS-Security.  Note that the certificate for this
authentication is a Eucalyptus-internal certificate that allows the
communication stack to determine that the message originated from the
correctly configured CLC.  In this way, the CC cannot be "spoofed" into
accepting messages from unauthorized CLCs.  The SOAP message processing also
compares the format of the message against a 
<a href="http://www.w3.org/TR/wsdl">WSDL</a> described interface to determine
that all of the fields in the message are syntactically correct.
<p>
The CC treats the correct receipt of a message that has been authenticated to
be from the CLC as an authorized message.  It uses the SOAP and WSDL checking
as part of validation.  In addition, it checks ranges of values in the request
to enure that they are valid.  These checks are necessary to guard against
possible misconfigurations (e.g. the CLC and CC do not agree on networking
parameters due to inconsistent configuration files).
<p>
The CC reserves network state (MAC address, private IP address) for the
instance as part of its Reservation subsystem and then triggers the next
two stages.

<h3>CC State Management and Resource Allocation</h3>

The CC is stateless in that all of its internal data structures are
continually refreshed through polling.  In the case of a
<code>euca-run-instances</code> request, when the request is received, the CC
chooses layer 2 MAC address and a layer 3 private IP address, selects an NC
using an internal scheduler, and formulates and sends a request to the NC.
No state persists in the CC after this message is sent but all state that the
CC needs to recover from the NC is transmitted to the NC as part of this
message.  The CC also triggers threads to install the necessary firewall and
NAT rules in the local Linux host on which it is running using iptables.
These rules in the kernel serve as the state for the CC -- it does not
maintain internal other in-memory data structures to maintain them.
Because the CC and NC cannot be co-located (the firewall an NAT rules
implemented by the CC assume a non-colocated NC) the web service stack
generates a WSDL-described SOAP message and routes the message (using the
certificate of the CC for authentication) to the NC.
<p>
The CC then proceeds to poll each NC on a regular duty cycle to determine the
state of the NC resources.  In the case of a <code>euca-run-stances</code>, it
will eventually "learn" from the NC that an instance exists on the NC.  This
state information from the NC is held in an in-memory cache that is completely
refreshed on each duty cycle while the CC waits for a polling request from the
CLC.  When the NC takes responsibility for the VM launch, a poll of the NC
will return a response carrying the state that the CC needs to report back to
the CLC indicating that the instance is "pending."  This state is saved in the
CC cache until the next CLC polling request when it is forward.  Simiklarly,
when the NC eventually runs the instance, the CC will determine that the
instance is running the next time it polls the NC.  It will cache that state
temporarily until the next CLC request then forward the information. 


-- disabled
-- vmtype not valid
-- min or max count < 0
-- network index length
-- network index out of bounds
-- capacity missing






</html>
